% Solve a Pattern Recognition Problem with a Neural Network
% MCS of 50x for statistics on best performing ANNs.

% Script generated by NPRTOOL
% Originally created Tue Jan 13 12:44:55 MST 2015 from HIL Model
% Modified for building wind damage modeling
% Authors: Stephanie F. Pilkington and Hussam Mahmoud
%
% This script assumes these variables are defined:
%
%   bldgs_inputs_all - input data.
%   bldgs_targets - target data.
%   These variables are with samples as rows and columns as elements
%   Code below requires a transpose so that columns are the samples
clc
clear all
close all

load model3_inputs
load bldgs_targets

inputs = transpose(model3_inputs);
targets = transpose(bldgs_targets); %transpose to get samples in columns
% Targets are sorted by damage state

Results(80,6)=zeros;

for i=1:50
% Create a Pattern Recognition Network
hiddenLayerSize = 10;   % Min should be 10 (as a starting point)
net = patternnet(hiddenLayerSize);

% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net.inputs{1}.processFcns = {'removeconstantrows','mapminmax'};
net.outputs{2}.processFcns = {'removeconstantrows','mapminmax'};

%Assign tranfer functions to each layer.
net.layers{1}.transferFcn = 'tansig';
net.layers{2}.transferFcn = 'tansig';


% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivide
net.divideFcn = 'dividerand';  % Divide data randomly
net.divideMode = 'sample';  % Divide up every sample
net.divideParam.trainRatio = 90/100;
% net.divideParam.valRatio = 15/100;
net.divideParam.testRatio = 10/100;

% For help on training function 'trainlm' type: help trainlm
% For a list of all training functions type: help nntrain
net.trainFcn = 'trainbr';  % Bayesian Regulation
%net.trainparam.mu_max = 1e5;

% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'mse';  % mean square error

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
% net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
%   'plotconfusion', 'plotroc'};

% Train the Network
[net,tr] = train(net,inputs,targets);

%Retrieve weights and biases
wb = getwb(net);
[b,IW,LW] = separatewb(net,wb);

% Test the Network
outputs = net(inputs);
errors = gsubtract(targets,outputs);
performance = perform(net,targets,outputs);

% Recalculate Training, Validation and Test Performance
trainTargets = targets .* tr.trainMask{1};
% valTargets = targets  .* tr.valMask{1};
testTargets = targets  .* tr.testMask{1};
trainPerformance = perform(net,trainTargets,outputs);
% valPerformance = perform(net,valTargets,outputs);
testPerformance = perform(net,testTargets,outputs);

% View the Network
%view(net)

% Show positive/ negative rates
% per(i,1) false negative rate
% per(i,2) false positive rate
% per(i,3) true positive rate
% per(i,4) true negative rate
[c,cm,ind,per] = confusion(targets,outputs);
FNR = mean(per(:,1));
FPR = mean(per(:,2));
TPR = mean(per(:,3));
TNR = mean(per(:,4));

Results(i,1) = c*100;
Results(i,2) = trainPerformance;
Results(i,3) = FNR;
Results(i,4) = FPR;
Results(i,5) = TPR;
Results(i,6) = TNR;

if c < 0.05
    % .2  for LM
    % .25 for RP
    % .05 for BR
    % Plots
    % Uncomment these lines to enable various plots.
    figure, plotperform(tr)
    figure, plottrainstate(tr)
    figure, plotconfusion(targets,outputs)
    figure, ploterrhist(errors)
    figure, plotroc(targets,outputs)
elseif c > 0.09
    % .65 for LM
    % .65 for RP
    % .09 for BR
    figure, plotperform(tr)
    figure, plottrainstate(tr)
    figure, plotconfusion(targets,outputs)
    figure, ploterrhist(errors)
    figure, plotroc(targets,outputs)
end
end
